# DST

- **What are the broad types of data?**
  1. **Structured Data**:
     - **Demographic Data**: Information about patients' age, gender, ethnicity, and geographical location.
     - **Clinical Data**: Data from electronic health records (EHRs) that includes medical history, diagnoses, medications, lab results, and vital signs.
     - **Billing and Claims Data**: Data related to healthcare services, costs, and insurance claims.
     - **Healthcare Utilisation Data**: Information about hospital admissions, emergency room visits, and outpatient visits.
     - **Time-Series Data**: Sequential data, such as vital signs or lab results recorded over time.
  2. **Unstructured Data**:
     - **Clinical Notes**: Free-text narratives written by healthcare providers, which may contain valuable information about symptoms, diagnoses, and treatment plans.
     - **Medical Imaging Data**: Radiology images, pathology slides, and other medical images that may require image processing and analysis.
     - **Textual Data from Research Articles**: Data extracted from scientific literature or clinical trial reports for research purposes.
  3. **Genomic and Molecular Data**:
     - **Genomic Sequencing Data**: Information from DNA and RNA sequencing experiments, including genetic variants and gene expression levels.
     - **Proteomic and Metabolomic Data**: Data on proteins and metabolites in biological samples.
  4. **Environmental and Geographic Data**:
     - **Environmental Factors**: Data on air quality, pollution levels, climate conditions, and other environmental factors that may impact health.
     - **Geospatial Data**: Geographic information systems (GIS) data that can be used for spatial analysis, such as mapping disease outbreaks or healthcare resource distribution.
  5. **Behavioural and Lifestyle Data**:
     - **Health Behaviour Surveys**: Data on lifestyle choices, including diet, physical activity, smoking, and alcohol consumption.
     - **Wearable Device Data**: Data from fitness trackers and health monitoring devices that record activity levels, sleep patterns, and heart rate.
  6. **Social Determinants of Health (SDOH) Data**:
     - **Socioeconomic Data**: Information about income, education, employment, housing, and social support networks.
     - **Community and Neighbourhood Data**: Data related to the social and economic characteristics of specific communities or neighbourhoods.
  7. **Administrative and Operational Data**:
     - **Healthcare Facility Data**: Information about hospital admissions, bed occupancy, and healthcare provider statistics.
     - **Supply Chain Data**: Data related to the procurement, distribution, and management of medical supplies and equipment.
  8. **Patient-Generated Data**:
     - **Patient Surveys**: Data collected directly from patients about their healthcare experiences and preferences.
     - **Patient-Reported Outcomes (PROs)**: Data on how patients perceive and report their health and well-being.
  ***
  - Clinical data from computerized provider order entry (CPOE)
  - Patient data from EPRs
  - Data from clinical support systems (written notes and prescriptions, medical imaging, lab work, pharmacy, insurance, and other administrative data)
  - Machine-generated medical data (like vital-sign monitors)
  - Patient-generated social media posts on Twitter, updates on Facebook and other platforms, blogs, and websites
  - Smartphone health apps
  - Emergency care data
  - News and medical journal articles
  [https://within3.com/blog/types-of-healthcare-data](https://within3.com/blog/types-of-healthcare-data)
  ***
- **What are the main types of resource?**
  Resources:
  - `sklearn` - often used for various classifiers
  - `pandas` - used for data handling (importing, preprocessing, arranging, modifying)
  - `numpy` - main mathematical tool for calculations, mostly used for other packages
  - `matplotlib` - for visualisation (or `plotly` for interactive graphs)
  - `seaborn` - statistical data visualisation tool that works well with pandas dataframes
- **What type of problems can the resources solve?**
  Tools (sklearn)
  - Standardisation & Normalisation:
    - `StandardScaler`, `MinMaxScaler`, `MaxAbsScaler`, `RobustScale`
  - Classifiers:
    - `RandomForestClassifier`, `ExtraTreesClassifier`, `LogisticRegression`, `DecisionTreeClassifier`, (`BaggingClassifier`, `AdaBoostClassifier`, `KNeighborsClassifier`)
  - Supervised learners:
    - `GaussianNB`,
- **Are there any generic data science resources that might be applicable? In
  what sense are they applicable?**
      Specific:

      - **Visualisation by Treemap/Sunburst** for data population using `plotly`
      - **Checking outcomes of standardisation/normalisation** with scatterplot and PDF plot
      - **Correlation heat map** for identification of correlation between multiple variables

      ---

      Generic:

      - structuring data → putting in SQL for ease of retrieval/analysis
      - data processing → remove outliers
      - calculating median → for quality assurance → faulty machine producing wrong results on occasion.
      - classification techniques like k-mean → distinction of disease
      - data visualisation → help interpret results [ref](https://demigos.com/blog-post/healthcare-data-visualization/)
      - modelling → Disease spread predictions
      - comparing data agains normal distribution
- **How might the approach be compared to other approaches, and/or applied
  across different datasets?**
      Most data preprocessing processes are exactly the same:

      1. Check data in general (shape, tail, head, etc)
      2. Remove missing values
      3. Remove duplicates (depends on a dataset)
      4. Relabelling or omitting columns
      5. Changing format of columns

      Then data visualisation:

      - Outliers: boxplots

Comparison of problems:

---

- **problem 1** (ref [https://www.kaggle.com/code/eslamfouad/fetal-health-autoeda](https://www.kaggle.com/code/eslamfouad/fetal-health-autoeda)):
  - **Dataset**: [https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification](https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification)
  - **Resource**: `fasteda`,`datacleaner`, `numpy`, `seaborn`, `pandas`,`pandas_profiling`,`scipy`,`sklearn`,`matplotlib`,
  - **Problems:**
    - **Data Analysis**
      - Overview (pandas) `head`
    - **Data Cleaning** and **Preprocessing**:
      - Fixing type (pandas) `astype`
      - Missing values (pandas) `isnull`,
      - Duplicates (pandas) `drop_duplicates`, `duplicated`,
      - Outliers (seaborn) `sns.boxplot`
      - Skewness [****Box-Cox, Yeo-Jhonson****] (matplotlib, seaborn, sklearn) `QuantileTransformer` and
      ```python
      plt.figure(figsize = (14,4))
      plt.subplot(121)
      sns.histplot(df_transformed[column])
      plt.title(column)

      plt.subplot(122)
      stats.probplot(df_transformed[column],dist = 'norm', plot = plt)
      plt.title(column)
      plt.show()
      ```
    - EDA
      - “`fast_eda`”
  -
- **problem 2** (ref [https://www.kaggle.com/code/eslamfouad/scaling-and-normalizing-fetal-health-data-set](https://www.kaggle.com/code/eslamfouad/scaling-and-normalizing-fetal-health-data-set))
  - **Dataset:** the same as problem 1
  - **Resource**: `pandas`, `numpy`, `matplotlib`, `seaborn`, `sklearn`,
  - Problems:
    - \***\*Data Inspection\*\*** (pandas) `head`, `tail`, `info`, `describe`, `isnull`, `skew`, `kurtosis`
    - **Standardisation** (pandas, sklearn) `StandardScaler`, `Scatterplot`, pdf plot,
    - \***\*Normalisation\*\*** (pandas, sklearn)
      - `MinMaxScaler`
      - `MaxAbsScaler`
      - `RobustScale`
      all followed by `Scatterplot` and pdf plot
- **problem 3** (ref [https://www.kaggle.com/code/ordorr/dsi473-fetal-health-challenge](https://www.kaggle.com/code/ordorr/dsi473-fetal-health-challenge))
  Interesting to look into relative to the first two problems as this one uses machine learning on the same dataset as previous two.
  - analysed in similar manner to fastEDA with `ProfileReport`
  - Then more specfic:
    - Count Plot (\***\*Check Imbalance Data\*\***)
    - Correlation Heat Map (**correlation between multiple variables as a color-coded matrix**)
    - Boxen Plot (\***\*Check Outlier\*\***)
  -

---

[https://www.kaggle.com/code/kairosart/machine-learning-for-mental-health-1](https://www.kaggle.com/code/kairosart/machine-learning-for-mental-health-1)

- Models (sklearn)
  `RandomForestClassifier` `ExtraTreesClassifier` `LogisticRegression` `DecisionTreeClassifier`
- Metrics (sklearn)
  `accuracy_score` `mean_squared_error` `precision_recall_curve` `cross_val_score`
- NN
  `MLPClassifier` `RandomizedSearchCV`
- Bagging (Bootstrap aggregating)
  `BaggingClassifier` `AdaBoostClassifier` `KNeighborsClassifier`
- Supervised machine learning classifier (_`Naive bayes`_)
  `GaussianNB`

---

**Interesting articles/books:**

- [Predictive Analytics in Health Care Using Machine Learning Tools and Techniques](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8250771)
- [Categorical Data Analysis](https://books.google.co.uk/books?hl=en&lr=&id=UOrr47-2oisC&oi=fnd&pg=PR13&dq=Predictive+Analytics+in+Healthcare+techniques+binary&ots=rQ1h6Kbo8G&sig=K64YgU_SJ-7Ja2rHsa7Ea2fJ98w#v=onepage&q=Predictive%20Analytics%20in%20Healthcare%20techniques%20binary&f=false) (book)
- [Firefly—Binary Cuckoo Search Technique based heart disease prediction in Big Data Analytics](https://pdf.sciencedirectassets.com/779469/3-s2.0-C20190012964/3-s2.0-B9780128202036000072/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFIaCXVzLWVhc3QtMSJHMEUCIQCrCn9fqFXXrb8oKAPfNLQUs4PHIKTrysRXnAFpRwApUQIgIaB1L6wlt6tUvwW9bGqCpg3b2aCA3qpInIm%2BJmptVqgqsgUIWxAFGgwwNTkwMDM1NDY4NjUiDAbHrnDffLJrgQ1J1SqPBf%2FGKJpyYDKbEvLuhXyb3eqRI5MN6ZRcxl88%2F%2BT2WAg0j74D83QBYllF7K%2BnJFWdiykbIvuXivLcgKa%2BxSJ%2FpX42BnnCEHx48Ti8N0zBzQuNyDZLT1zvGBpYasvF9W0Tf0NjPJCYtBRycm0rwmAZDod%2FJIzbDTkvBdvPJWhvU7cJ9jkGp1xRQWmQAj56Wo7Ln0rMO7tw1kdnQ5SamtuXEOtf8ETzFxv5XBSqjQ7WoVfFX%2BJk6jMrXdikTTSJS4h3dpjDEAQaa57Dv4MKHsQ4bZkPTETQr9oqauyUoVzGScvpFmAGnmoqBsS48XqjAfvvtBnBHIk%2B0W95B0tKR5S0RkK6gPk%2BkICLplUbL8DRsAN2U%2BCIA3Zch%2FsLYuecGfvDDXrrJtFlKqDbYKUtReTL5dwFA111y7WyY9M059QkJwlhUb9Gs3zmXqrGjIY7WEcj6QC05VCBQQpqYtsEkHQbcbSwN9o4a2mCPhFKlojeeX6Z3uO2faMShvjYqyoGtL36zTqzrMwQTpMTyiyKwoDgRy%2FMzLOQDFIoSJrhd1tC%2FeD3Q5Mc1mkL8DO%2FzHrsdtDYlWuTH10bRMv0h%2Bk4rdzLkNkMF50GpNA%2B6qhhb9%2FddcKbO7v7sYxFZsd9I4X%2BSVS6bCiIMFabH1kfdBsywi4FJ1wjc5%2FXh7%2BPD7yz%2FJHQkXAMC3m%2FE3c2NZ9AgYQuxibA4C0N8BUPE%2F1c8O5cC%2BDj0XmO%2BHRBp8fIB7ZumhovcuG6OW2nU2xj10vMMfBIle5%2BoMzeSQiBxM88t0zofv6qKSwhrKO7Rrea3r0KivA1li%2Bp1PHMl1d9M6N5a49rpOBYFqsj7s9inxBvW6g7skYhnTVJlbp3BsW967TecL6vuoMw2IX6qAY6sQG3jb2fJ%2FVdHB%2FcOqkmyBOXbn%2FIE2b3XIeczV4RQa9HE9g%2Binbl%2Fjse7fhskuQjve6T0LwAZs5HGlx4FGbiGXxnCW7iwUqYGIECN9BkjLG5Kpt38Wq%2FLJxziFJHvhRdnqgkeIGfaHzYVOqOLzvSyhiAdaTwLTG52ub7DS4SsTUIt8aTzeOZ5WFqRg7ok9iJZjOpJuIiBwpu1TGaLXXrW1j6XasvqW87wMfsCF7%2BtignJGA%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20231005T101707Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY3WPBLINK%2F20231005%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7e8f00144b6a5d9c1252d97ed435d81662d4f22ba4d8c304cdbbcbc35f1ff9d1&hash=7ad2dd40aa732d5823e89b50998467b5508538ba13fc26167284a05337439396&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=B9780128202036000072&tid=spdf-40a9e7a9-49be-4ba3-8caa-ae6033fb4f72&sid=e5d10b033fb7e64a006ba902d16c8caca8f8gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1d015b50575b0b5d0604&rr=8114e9bf6d12532d&cc=gb)
  Fetal growth curves, the classic case of big health data, are used to predict coronary heart disease. The proposed framework introduces the idea of summarizing large big data (inputs) in multidimensional scenarios in which known data mining methods such as preprocessing, optimal selection of features and forecasts are used. The dataset contains many random and variable values and can lead to incorrect results. Therefore, when dealing with these values, the utmost care is needed to obtain the best performance. Therefore, data creation before optimal function creation is processed using bacterial foraging optimization (BFO) before sample creation. It defines a multidimensional mining approach as a whole that addresses complex healthcare environments. This work aims to predict the risk of coronary heart disease (CAD) using machine learning algorithms such as Firefly—Binary Cuckoo Search (FFBCS). We also suggest a preliminary analysis of the performance of the framework.

---

Questions answered in context of machine learning based on this research with respect to big data processing:

[https://www.aimspress.com/aimspress-data/bdia/2020/1/PDF/bigdia-05-005.pdf](https://www.aimspress.com/aimspress-data/bdia/2020/1/PDF/bigdia-05-005.pdf)

- abstract
  This paper discusses different machine learning algorithms that were applied to various healthcare data. Also, the challenges of processing, handling big data, and their applications. The scope of the paper is to elaborate on the application of machine learning algorithms and the need for handling and utilizing big data from a different perspective.
- **What are the broad types of data?**
  > Big data originally illustrate the volume, velocity, and **variety of data that comes from various data production time by health care providers** that contain information relevant to a patient’s care, including to **demographics**, **diagnoses**, **medical procedures**, **medications**, **vital signs**, **immunizations**, **laboratory results**, and **radiology images**. […]
  > Big data can be classified by 5Vs as follows: **Volume**; **Velocity**: The rate at which the data is generated truly represents big data. […] Most of the health data are in form of paper files, X-ray films, and scripts and the growth rate of such data is now immensely increasing; **Variety**: […] the different types of data formats include **database**, **excel**, and **CSV**, which can be stored in a plain text file. In existence, health data also are structured, unstructured, and semi-structured. An example of structured information is clinical data, instead, data such as **doctor notes**, **paper prescriptions**, **office medical records**, **images**, and **radiograph films** are unstructured or semi-structured; **Veracity**; **Value**: The benefits and costs of analyzing and collecting big data are more important things when doing big data analytics […]
  - Big data sources for healthcare include, the Internet of Things (IoT), Electronic Medical
    Record/Electronic Health Record (EMR/EHR) contains patient’s medical history, diagnoses,
    medications, treatment plans, allergies, laboratory and test results, genomic sequencing, Medical Imaging, Insurance Providers and other clinical data.
- **What type of problems can the resources solve?**
  ![ref. [https://www.aimspress.com/aimspress-data/bdia/2020/1/PDF/bigdia-05-005.pdf](https://www.aimspress.com/aimspress-data/bdia/2020/1/PDF/bigdia-05-005.pdf)](DST%205a30d14fab30455584cf78de926d1340/Screenshot_2023-10-05_at_11.23.05.png)
  ref. [https://www.aimspress.com/aimspress-data/bdia/2020/1/PDF/bigdia-05-005.pdf](https://www.aimspress.com/aimspress-data/bdia/2020/1/PDF/bigdia-05-005.pdf)
- **Are there any generic data science resources that might be applicable? In
  what sense are they applicable?**
      ![table 2.png](DST%205a30d14fab30455584cf78de926d1340/table_2.png)
- **How might the approach be compared to other approaches, and/or applied
  across different datasets?**
      > There are two phases in classification, first is the learning process phase in which huge training data sets are supplied and inquiry takes place then rules and patterns are created. Then the execution of the second phase starts that is evaluation or test of data sets and archives the accuracy of a classification pattern. There was an approach that creates a binary search tree (BST) to be used following by the KNN to speed up the big data classification
      >

      **ref**. Hassanat ABA, (2018) Furthest-pair-based binary search tree for speeding big data classification using K-nearest neighbors. Big Data 6: 225–235.

Questions with respect to work I’ve done:

- **What are the broad types of data?**
  Most of the data in dataset for breast cancer is numerical data (decimal value) apart from the value we want to predict, the diagnose which is categorical variables (in original data as M and B).
  We have 29 features so data is high dimensional. We also can notice that data is highly correlated within predictors
- **What are the main types of resource?**
  As we are modeling a binary outcome, most resources used in this problem are binary classifiers. Such as:
  - Logistic Regression
    - This is an easy and fast classifier using sigmoid function. However logistic regression may have problems because of multicollinearity or high dimensionality (ref. [https://www.researchgate.net/publication/336213669_Diagnosing_Multicollinearity_of_Logistic_Regression_Model](https://www.researchgate.net/publication/336213669_Diagnosing_Multicollinearity_of_Logistic_Regression_Model)) as “Multicollinearity will cause unstable estimates and inaccurate variances that affects confidence intervals and hypothesis tests.” Hence this could benefit from calculating VIF (Variance Inflation Factor).
    - Standard logistic regression is susceptible to noisy data.
  - SVC (support vector classifier)
    - From consideration of discussion [https://stats.stackexchange.com/questions/95340/comparing-svm-and-logistic-regression](https://stats.stackexchange.com/questions/95340/comparing-svm-and-logistic-regression), the following was considered:
    - SVM have kernel function which computes the similarity between data points thus allowing SVM to capture complex patterns and nonlinear relationships between features. (ref. [https://www.geeksforgeeks.org/ml-non-linear-svm/](https://www.geeksforgeeks.org/ml-non-linear-svm/))
    - Even though soft margin can allow some misclassification, SVM can be less prone to outliers, as support vectors are used in the algorithm. Hence, SVM would be less prone to overfit data.
    - When number of features large relative to sample size, use logistic regression or SVM with linear kernel ([https://medium.com/axum-labs/logistic-regression-vs-support-vector-machines-svm-c335610a3d16](https://medium.com/axum-labs/logistic-regression-vs-support-vector-machines-svm-c335610a3d16))
  - ANN
  - DTS (Decision tree classifier)
  Standard scalers was essential as in normalised feature classes with vast numerical differences.
- **What type of problems can the resources solve?**
  - While LR and SVC can solve binary calcification problems however both generalisable to multi-class problems. However, since standard logistic regression does not consider the impact of data redundancy on classification, it would be more likely used on small sets.
- **Are there any generic data science resources that might be applicable? In
  what sense are they applicable?**
      Assuming linearity:

      - RandomizedSearchCV - Randomized search on hyper parameters.
- **How might the approach be compared to other approaches, and/or applied
  across different datasets?**
      Assuming linearity

      - GridSearchCV - Exhaustive search over specified parameter values for an estimator.

      or Without assuming linearity.

      It makes sense to standardise data due to large disparity in terms of the scales of the predictors – in particular, the area and perimeter type variables are on a much larger scale than the others.
